/**
*  Copyright (c) 2011, Alex Theodoridis
*  All rights reserved.

*  Redistribution and use in source and binary forms, with
*  or without modification, are permitted provided that the
*  following conditions are met:
*  Redistributions of source code must retain the above
*  copyright notice, this list of conditions and the following disclaimer.
*  Redistributions in binary form must reproduce the above
*  copyright notice, this list of conditions and the following
*  disclaimer in the documentation and/or other materials
*  provided with the distribution.

*  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS
*  AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
*  INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
*  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
*  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
*  ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
*  OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
*  PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
*  OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
*  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
*  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
*  ANY WAY OUT OF THE USE OF THIS SOFTWARE,
*  EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE
*/

#ifndef _OUTPUTNEURALLAYER_H
#define _OUTPUTNEURALLAYER_H

#include <NeuralNetwork/LearningAlgorithm/BackPropagation/ANeuralLayer.h>

namespace nn {

    namespace bp {
/*
template<class Var>
class OutputNeuralLayer {
public:
    OutputNeuralLayer(
        const typename utils::SharedPtr<NeuralLayer<Var> >& neuralLayer,
        float varP);
    bool calculateLayerDeltas(
        const utils::SharedPtr<INeuralLayer<Var> >& affectedLayer,
        const NNSamplesSet<Var>* dataSet = NULL);
    virtual ~OutputNeuralLayer() throw ();

};

template<class Var>
OutputNeuralLayer<Var>::OutputNeuralLayer(
    const typename utils::SharedPtr<NeuralLayer<Var> >& neuralLayer,
    float varP) :
        ANeuralLayer<Var> (neuralLayer, varP) {
}

template<class Var>
OutputNeuralLayer<Var>::~OutputNeuralLayer() throw () {
}



}

}
*/
#endif /* _OUTPUTNEURALLAYER_H */

// kate: indent-mode cstyle; space-indent on; indent-width 0;
